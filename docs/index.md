---
title: Inference Client Title Test
category: 645b1e71f6dfd506df5acc01
hidden: false
---

# Welcome to the Inference Client

The Inference Client is a powerful library that provides a simple and efficient way to use Jina AI's Inference platform. 
Inference provides a range of AI models for common tasks such as visual reasoning, question answering, and embedding modalities like texts and images. 
With the Inference Client, you can easily select the task and model of your choice and integrate the API call into your workflow with zero technical overhead.

The Inference Client is designed to be easy to use, with a simple and intuitive API that allows you to perform common tasks with just a few lines of code. 
Whether you're a software developer looking to integrate AI models into your application, or a data scientist looking to experiment with different models and configurations, the Inference Client is the perfect tool for the job.
    
ü§ù **Easy to integrate**: With a simple and intuitive API, the Inference Client allows you to seamlessly integrate AI models into your existing workflows with zero technical overhead.

üåü **Wide range of models**: Inference provides a wide range of pre-trained models for common tasks. 
Whether you need to encode data into embeddings, generate captions for images, or answer questions related to images, the Inference Client has you covered.

üí® **Lightning-fast performance**: The Inference Client is designed to be fast and efficient, allowing you to process large volumes of data in real-time.

üë®‚Äçüíª **Developer-friendly**: The Inference Client is designed with developers in mind, with easy-to-understand documentation and a flexible API that allows you to customize the client to suit your needs.


## Installation

To install the Inference Client, you'll need to have Python 3.8 or later and pip (the Python package installer) installed on your system. 
Once you have those installed, simply run the following command:

```bash
pip install inference-client
```

This will install the Inference Client and any necessary dependencies.


```{toctree}
:caption: User Guides
:hidden:

getting_started/index
performing_tasks/index
```

```{toctree}
:caption: Developer Reference
:hidden:
:maxdepth: 1

api/inference_client
```

[//]: # (---)

[//]: # ()
[//]: # ({ref}`genindex` | {ref}`modindex`)

